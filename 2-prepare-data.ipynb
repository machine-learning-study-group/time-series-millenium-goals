{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Data\n",
    "\n",
    "From https://machinelearningmastery.com/process-for-working-through-machine-learning-problems/\n",
    "\n",
    "I preface data preparation with a data analysis phase that involves summarizing the attributes and visualizing them using scatter plots and histograms. I also like to describe in detail each attribute and relationships between attributes. This grunt work forces me to think about the data in the context of the problem before it is lost to the algorithms\n",
    "\n",
    "The actual data preparation process is three step as follows:\n",
    "\n",
    "* Step 1: Data Selection: Consider what data is available, what data is missing and what data can be removed.\n",
    "* Step 2: Data Preprocessing: Organize your selected data by formatting, cleaning and sampling from it.\n",
    "* Step 3: Data Transformation: Transform preprocessed data ready for machine learning by engineering features using scaling, attribute decomposition and attribute aggregation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expands columns to maximum width\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve resources\n",
    "\n",
    "The data directory will be ignored by `git` and you will need to retrieve manually the resources.\n",
    "\n",
    "You can retrieve the contents of this zip file into the data subdirectory from the link: \n",
    "https://s3.amazonaws.com/drivendata/data/1/public/cd238763-ed29-4a46-8584-f9334d57ec94.zip\n",
    "You should have `data/TrainingSet.csv` and `data/SubmissionRows.csv`.\n",
    "\n",
    "You will need as well to put the `countryinfo.py` file in the data/ folder: \n",
    "https://gist.githubusercontent.com/pamelafox/986163/raw/f5f9db4f1b287804fd07ffb3296ed0036292bc7a/countryinfo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/TrainingSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>...</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Series_Code</th>\n",
       "      <th>Series_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.769214</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>allsi.bi_q1</td>\n",
       "      <td>(%) Benefits held by 1st 20% population - All Social Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.027746</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>allsp.bi_q1</td>\n",
       "      <td>(%) Benefits held by 1st 20% population - All Social Protection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1972  1973  1974  1975  1976  1977  1978  1979  1980  1981  ...  2001  \\\n",
       "0 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    ... NaN     \n",
       "1 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    ... NaN     \n",
       "\n",
       "   2002  2003  2004  2005  2006      2007  Country_Name  Series_Code  \\\n",
       "0 NaN   NaN   NaN   NaN   NaN    3.769214  Afghanistan   allsi.bi_q1   \n",
       "1 NaN   NaN   NaN   NaN   NaN    7.027746  Afghanistan   allsp.bi_q1   \n",
       "\n",
       "                                                       Series_Name  \n",
       "0  (%) Benefits held by 1st 20% population - All Social Insurance   \n",
       "1  (%) Benefits held by 1st 20% population - All Social Protection  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first few lines to get an idea what the actual data look like\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>...</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Series_Code</th>\n",
       "      <th>Series_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286116</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>SG.VAW.REFU.ZS</td>\n",
       "      <td>Women who believe a husband is justified in beating his wife when she refuses sex with him (%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286117</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>57.5</td>\n",
       "      <td>57.7</td>\n",
       "      <td>57.9</td>\n",
       "      <td>58.1</td>\n",
       "      <td>58.3</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>SH.DYN.AIDS.FE.ZS</td>\n",
       "      <td>Women's share of population ages 15+ living with HIV (%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1972  1973  1974  1975  1976  1977  1978  1979  1980  1981  ...  2001  \\\n",
       "286116 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    ... NaN     \n",
       "286117 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    ...  57.0   \n",
       "\n",
       "        2002  2003  2004  2005  2006  2007  Country_Name        Series_Code  \\\n",
       "286116 NaN   NaN   NaN   NaN    24.3 NaN    Zimbabwe      SG.VAW.REFU.ZS      \n",
       "286117  57.2  57.5  57.7  57.9  58.1  58.3  Zimbabwe      SH.DYN.AIDS.FE.ZS   \n",
       "\n",
       "                                                                                           Series_Name  \n",
       "286116  Women who believe a husband is justified in beating his wife when she refuses sex with him (%)  \n",
       "286117  Women's share of population ages 15+ living with HIV (%)                                        \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last few lines\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column looks like a row ID, let's double check to see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0].nunique() == df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are as many unique rows in the index column as in the row dataframe dimension, so I'm going to use `index_col=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/TrainingSet.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1972 [YR1972]</th>\n",
       "      <th>1973 [YR1973]</th>\n",
       "      <th>1974 [YR1974]</th>\n",
       "      <th>1975 [YR1975]</th>\n",
       "      <th>1976 [YR1976]</th>\n",
       "      <th>1977 [YR1977]</th>\n",
       "      <th>1978 [YR1978]</th>\n",
       "      <th>1979 [YR1979]</th>\n",
       "      <th>1980 [YR1980]</th>\n",
       "      <th>1981 [YR1981]</th>\n",
       "      <th>...</th>\n",
       "      <th>2001 [YR2001]</th>\n",
       "      <th>2002 [YR2002]</th>\n",
       "      <th>2003 [YR2003]</th>\n",
       "      <th>2004 [YR2004]</th>\n",
       "      <th>2005 [YR2005]</th>\n",
       "      <th>2006 [YR2006]</th>\n",
       "      <th>2007 [YR2007]</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Series Code</th>\n",
       "      <th>Series Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.769214</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>allsi.bi_q1</td>\n",
       "      <td>(%) Benefits held by 1st 20% population - All Social Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.027746</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>allsp.bi_q1</td>\n",
       "      <td>(%) Benefits held by 1st 20% population - All Social Protection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.244887</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>allsa.bi_q1</td>\n",
       "      <td>(%) Benefits held by 1st 20% population - All Social Safety Nets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1972 [YR1972]  1973 [YR1973]  1974 [YR1974]  1975 [YR1975]  1976 [YR1976]  \\\n",
       "0 NaN            NaN            NaN            NaN            NaN              \n",
       "1 NaN            NaN            NaN            NaN            NaN              \n",
       "2 NaN            NaN            NaN            NaN            NaN              \n",
       "\n",
       "   1977 [YR1977]  1978 [YR1978]  1979 [YR1979]  1980 [YR1980]  1981 [YR1981]  \\\n",
       "0 NaN            NaN            NaN            NaN            NaN              \n",
       "1 NaN            NaN            NaN            NaN            NaN              \n",
       "2 NaN            NaN            NaN            NaN            NaN              \n",
       "\n",
       "   ...  2001 [YR2001]  2002 [YR2002]  2003 [YR2003]  2004 [YR2004]  \\\n",
       "0  ... NaN            NaN            NaN            NaN              \n",
       "1  ... NaN            NaN            NaN            NaN              \n",
       "2  ... NaN            NaN            NaN            NaN              \n",
       "\n",
       "   2005 [YR2005]  2006 [YR2006]  2007 [YR2007]  Country Name  Series Code  \\\n",
       "0 NaN            NaN             3.769214       Afghanistan   allsi.bi_q1   \n",
       "1 NaN            NaN             7.027746       Afghanistan   allsp.bi_q1   \n",
       "2 NaN            NaN             8.244887       Afghanistan   allsa.bi_q1   \n",
       "\n",
       "                                                        Series Name  \n",
       "0  (%) Benefits held by 1st 20% population - All Social Insurance    \n",
       "1  (%) Benefits held by 1st 20% population - All Social Protection   \n",
       "2  (%) Benefits held by 1st 20% population - All Social Safety Nets  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980',\n",
       "       '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989',\n",
       "       '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998',\n",
       "       '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007',\n",
       "       'Country_Name', 'Series_Code', 'Series_Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the column names?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns to remove gaps and unnecessary info and to ease further coding when selecting the sets of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [year[:4] for year in df.columns][:-3] + [col.replace(' ', '_') for col in df.columns.values[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>64945.0</td>\n",
       "      <td>1.630638e+11</td>\n",
       "      <td>4.261616e+12</td>\n",
       "      <td>-1.047939e+14</td>\n",
       "      <td>3.176702</td>\n",
       "      <td>63.940000</td>\n",
       "      <td>5.007000e+06</td>\n",
       "      <td>2.681335e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>64443.0</td>\n",
       "      <td>1.839488e+11</td>\n",
       "      <td>4.749746e+12</td>\n",
       "      <td>-1.128889e+14</td>\n",
       "      <td>3.550009</td>\n",
       "      <td>66.317365</td>\n",
       "      <td>7.131000e+06</td>\n",
       "      <td>2.943467e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>64966.0</td>\n",
       "      <td>2.089534e+11</td>\n",
       "      <td>5.378336e+12</td>\n",
       "      <td>-7.134161e+13</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>70.485627</td>\n",
       "      <td>9.250000e+06</td>\n",
       "      <td>3.186506e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>66973.0</td>\n",
       "      <td>2.148826e+11</td>\n",
       "      <td>5.647070e+12</td>\n",
       "      <td>-8.269588e+13</td>\n",
       "      <td>3.671917</td>\n",
       "      <td>71.886131</td>\n",
       "      <td>1.108200e+07</td>\n",
       "      <td>3.383541e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>67717.0</td>\n",
       "      <td>2.321517e+11</td>\n",
       "      <td>6.120314e+12</td>\n",
       "      <td>-9.735652e+13</td>\n",
       "      <td>4.595300</td>\n",
       "      <td>74.563536</td>\n",
       "      <td>1.290000e+07</td>\n",
       "      <td>3.586152e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>69735.0</td>\n",
       "      <td>2.413682e+11</td>\n",
       "      <td>6.398377e+12</td>\n",
       "      <td>-9.433422e+13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>78.944621</td>\n",
       "      <td>1.540950e+07</td>\n",
       "      <td>3.895869e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>69763.0</td>\n",
       "      <td>2.540583e+11</td>\n",
       "      <td>6.710724e+12</td>\n",
       "      <td>-9.495898e+13</td>\n",
       "      <td>4.901495</td>\n",
       "      <td>78.638080</td>\n",
       "      <td>1.922850e+07</td>\n",
       "      <td>4.254506e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>69906.0</td>\n",
       "      <td>2.742810e+11</td>\n",
       "      <td>7.213662e+12</td>\n",
       "      <td>-5.362479e+13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>81.408655</td>\n",
       "      <td>2.409375e+07</td>\n",
       "      <td>4.556262e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>75250.0</td>\n",
       "      <td>2.674858e+11</td>\n",
       "      <td>7.381164e+12</td>\n",
       "      <td>-5.649790e+13</td>\n",
       "      <td>5.682373</td>\n",
       "      <td>81.829695</td>\n",
       "      <td>2.419225e+07</td>\n",
       "      <td>5.039050e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>78034.0</td>\n",
       "      <td>2.774415e+11</td>\n",
       "      <td>7.942777e+12</td>\n",
       "      <td>-5.437839e+13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>78.137173</td>\n",
       "      <td>2.317875e+07</td>\n",
       "      <td>5.815794e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>79016.0</td>\n",
       "      <td>2.855765e+11</td>\n",
       "      <td>8.172645e+12</td>\n",
       "      <td>-3.426626e+13</td>\n",
       "      <td>4.960081</td>\n",
       "      <td>80.318724</td>\n",
       "      <td>2.256215e+07</td>\n",
       "      <td>5.758716e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>78982.0</td>\n",
       "      <td>3.044762e+11</td>\n",
       "      <td>8.692754e+12</td>\n",
       "      <td>-5.200444e+13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>79.300002</td>\n",
       "      <td>2.350450e+07</td>\n",
       "      <td>6.003113e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>79532.0</td>\n",
       "      <td>3.245888e+11</td>\n",
       "      <td>9.276417e+12</td>\n",
       "      <td>-3.946788e+13</td>\n",
       "      <td>5.196830</td>\n",
       "      <td>79.811320</td>\n",
       "      <td>2.427000e+07</td>\n",
       "      <td>6.447141e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>81017.0</td>\n",
       "      <td>3.427618e+11</td>\n",
       "      <td>9.772436e+12</td>\n",
       "      <td>-3.687346e+13</td>\n",
       "      <td>5.065000</td>\n",
       "      <td>79.066896</td>\n",
       "      <td>2.448900e+07</td>\n",
       "      <td>6.806750e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>81455.0</td>\n",
       "      <td>3.562208e+11</td>\n",
       "      <td>1.013773e+13</td>\n",
       "      <td>-3.562521e+13</td>\n",
       "      <td>5.228311</td>\n",
       "      <td>78.127934</td>\n",
       "      <td>2.689850e+07</td>\n",
       "      <td>7.329650e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>82752.0</td>\n",
       "      <td>3.756705e+11</td>\n",
       "      <td>1.065710e+13</td>\n",
       "      <td>-3.890910e+13</td>\n",
       "      <td>5.006363</td>\n",
       "      <td>76.738150</td>\n",
       "      <td>2.689311e+07</td>\n",
       "      <td>8.034300e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>83242.0</td>\n",
       "      <td>4.052722e+11</td>\n",
       "      <td>1.146437e+13</td>\n",
       "      <td>-6.349069e+13</td>\n",
       "      <td>5.077723</td>\n",
       "      <td>74.985556</td>\n",
       "      <td>2.981823e+07</td>\n",
       "      <td>8.865110e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>86331.0</td>\n",
       "      <td>4.554388e+11</td>\n",
       "      <td>1.279491e+13</td>\n",
       "      <td>-5.612962e+13</td>\n",
       "      <td>4.595098</td>\n",
       "      <td>75.668400</td>\n",
       "      <td>2.869550e+07</td>\n",
       "      <td>9.735230e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>106955.0</td>\n",
       "      <td>4.132816e+11</td>\n",
       "      <td>1.255151e+13</td>\n",
       "      <td>-4.287495e+13</td>\n",
       "      <td>5.045321</td>\n",
       "      <td>69.400000</td>\n",
       "      <td>1.332700e+07</td>\n",
       "      <td>1.047622e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>106991.0</td>\n",
       "      <td>4.546238e+11</td>\n",
       "      <td>1.344050e+13</td>\n",
       "      <td>-5.221512e+13</td>\n",
       "      <td>5.050660</td>\n",
       "      <td>66.542463</td>\n",
       "      <td>1.692168e+07</td>\n",
       "      <td>1.097263e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>112243.0</td>\n",
       "      <td>4.662766e+11</td>\n",
       "      <td>1.389502e+13</td>\n",
       "      <td>-5.054790e+13</td>\n",
       "      <td>4.708118</td>\n",
       "      <td>65.160000</td>\n",
       "      <td>1.414500e+07</td>\n",
       "      <td>1.153124e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>114553.0</td>\n",
       "      <td>4.939287e+11</td>\n",
       "      <td>1.466769e+13</td>\n",
       "      <td>-7.303608e+13</td>\n",
       "      <td>4.570544</td>\n",
       "      <td>64.571959</td>\n",
       "      <td>1.545200e+07</td>\n",
       "      <td>1.192591e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>116823.0</td>\n",
       "      <td>5.562240e+11</td>\n",
       "      <td>1.599025e+13</td>\n",
       "      <td>-6.360371e+13</td>\n",
       "      <td>4.860058</td>\n",
       "      <td>65.900002</td>\n",
       "      <td>1.827500e+07</td>\n",
       "      <td>1.238312e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>124468.0</td>\n",
       "      <td>5.777780e+11</td>\n",
       "      <td>1.681787e+13</td>\n",
       "      <td>-7.682327e+13</td>\n",
       "      <td>5.181426</td>\n",
       "      <td>65.699997</td>\n",
       "      <td>1.779400e+07</td>\n",
       "      <td>1.342285e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>124374.0</td>\n",
       "      <td>6.334248e+11</td>\n",
       "      <td>1.817110e+13</td>\n",
       "      <td>-9.040236e+13</td>\n",
       "      <td>5.254441</td>\n",
       "      <td>65.534551</td>\n",
       "      <td>1.917926e+07</td>\n",
       "      <td>1.444873e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>125686.0</td>\n",
       "      <td>6.777829e+11</td>\n",
       "      <td>1.919710e+13</td>\n",
       "      <td>-7.724689e+13</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>65.400002</td>\n",
       "      <td>1.900300e+07</td>\n",
       "      <td>1.517223e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>125944.0</td>\n",
       "      <td>7.079045e+11</td>\n",
       "      <td>1.927225e+13</td>\n",
       "      <td>-1.014742e+14</td>\n",
       "      <td>4.902281</td>\n",
       "      <td>64.235994</td>\n",
       "      <td>1.870445e+07</td>\n",
       "      <td>1.348416e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>130880.0</td>\n",
       "      <td>7.214590e+11</td>\n",
       "      <td>1.975110e+13</td>\n",
       "      <td>-9.646140e+13</td>\n",
       "      <td>5.264969</td>\n",
       "      <td>65.699997</td>\n",
       "      <td>1.300000e+07</td>\n",
       "      <td>1.324599e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>140547.0</td>\n",
       "      <td>7.396189e+11</td>\n",
       "      <td>2.055262e+13</td>\n",
       "      <td>-9.216180e+13</td>\n",
       "      <td>5.304083</td>\n",
       "      <td>62.707958</td>\n",
       "      <td>6.544000e+06</td>\n",
       "      <td>1.389770e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>136783.0</td>\n",
       "      <td>8.236331e+11</td>\n",
       "      <td>2.240717e+13</td>\n",
       "      <td>-6.621060e+13</td>\n",
       "      <td>5.249579</td>\n",
       "      <td>63.916000</td>\n",
       "      <td>1.038850e+07</td>\n",
       "      <td>1.646322e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>140315.0</td>\n",
       "      <td>8.834342e+11</td>\n",
       "      <td>2.412411e+13</td>\n",
       "      <td>-5.635700e+13</td>\n",
       "      <td>5.269189</td>\n",
       "      <td>63.299999</td>\n",
       "      <td>9.278000e+06</td>\n",
       "      <td>1.821833e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>139159.0</td>\n",
       "      <td>9.691983e+11</td>\n",
       "      <td>2.612031e+13</td>\n",
       "      <td>-1.853552e+14</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>64.522871</td>\n",
       "      <td>1.200000e+07</td>\n",
       "      <td>2.013675e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>142379.0</td>\n",
       "      <td>1.054572e+12</td>\n",
       "      <td>2.874833e+13</td>\n",
       "      <td>-1.515222e+14</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>62.906202</td>\n",
       "      <td>1.066050e+07</td>\n",
       "      <td>2.295826e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>161544.0</td>\n",
       "      <td>1.057680e+12</td>\n",
       "      <td>3.047457e+13</td>\n",
       "      <td>-1.350005e+14</td>\n",
       "      <td>5.206670</td>\n",
       "      <td>57.378561</td>\n",
       "      <td>8.484250e+06</td>\n",
       "      <td>2.774281e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>158888.0</td>\n",
       "      <td>1.203163e+12</td>\n",
       "      <td>3.469590e+13</td>\n",
       "      <td>-1.422689e+14</td>\n",
       "      <td>5.206982</td>\n",
       "      <td>55.474170</td>\n",
       "      <td>1.025022e+07</td>\n",
       "      <td>3.339217e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>161596.0</td>\n",
       "      <td>1.353147e+12</td>\n",
       "      <td>4.002108e+13</td>\n",
       "      <td>-1.691820e+14</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>55.043033</td>\n",
       "      <td>8.599101e+06</td>\n",
       "      <td>3.950893e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count          mean           std           min       25%        50%  \\\n",
       "1972  64945.0   1.630638e+11  4.261616e+12 -1.047939e+14  3.176702  63.940000   \n",
       "1973  64443.0   1.839488e+11  4.749746e+12 -1.128889e+14  3.550009  66.317365   \n",
       "1974  64966.0   2.089534e+11  5.378336e+12 -7.134161e+13  4.000000  70.485627   \n",
       "1975  66973.0   2.148826e+11  5.647070e+12 -8.269588e+13  3.671917  71.886131   \n",
       "1976  67717.0   2.321517e+11  6.120314e+12 -9.735652e+13  4.595300  74.563536   \n",
       "1977  69735.0   2.413682e+11  6.398377e+12 -9.433422e+13  5.000000  78.944621   \n",
       "1978  69763.0   2.540583e+11  6.710724e+12 -9.495898e+13  4.901495  78.638080   \n",
       "1979  69906.0   2.742810e+11  7.213662e+12 -5.362479e+13  5.000000  81.408655   \n",
       "1980  75250.0   2.674858e+11  7.381164e+12 -5.649790e+13  5.682373  81.829695   \n",
       "1981  78034.0   2.774415e+11  7.942777e+12 -5.437839e+13  5.000000  78.137173   \n",
       "1982  79016.0   2.855765e+11  8.172645e+12 -3.426626e+13  4.960081  80.318724   \n",
       "1983  78982.0   3.044762e+11  8.692754e+12 -5.200444e+13  5.000000  79.300002   \n",
       "1984  79532.0   3.245888e+11  9.276417e+12 -3.946788e+13  5.196830  79.811320   \n",
       "1985  81017.0   3.427618e+11  9.772436e+12 -3.687346e+13  5.065000  79.066896   \n",
       "1986  81455.0   3.562208e+11  1.013773e+13 -3.562521e+13  5.228311  78.127934   \n",
       "1987  82752.0   3.756705e+11  1.065710e+13 -3.890910e+13  5.006363  76.738150   \n",
       "1988  83242.0   4.052722e+11  1.146437e+13 -6.349069e+13  5.077723  74.985556   \n",
       "1989  86331.0   4.554388e+11  1.279491e+13 -5.612962e+13  4.595098  75.668400   \n",
       "1990  106955.0  4.132816e+11  1.255151e+13 -4.287495e+13  5.045321  69.400000   \n",
       "1991  106991.0  4.546238e+11  1.344050e+13 -5.221512e+13  5.050660  66.542463   \n",
       "1992  112243.0  4.662766e+11  1.389502e+13 -5.054790e+13  4.708118  65.160000   \n",
       "1993  114553.0  4.939287e+11  1.466769e+13 -7.303608e+13  4.570544  64.571959   \n",
       "1994  116823.0  5.562240e+11  1.599025e+13 -6.360371e+13  4.860058  65.900002   \n",
       "1995  124468.0  5.777780e+11  1.681787e+13 -7.682327e+13  5.181426  65.699997   \n",
       "1996  124374.0  6.334248e+11  1.817110e+13 -9.040236e+13  5.254441  65.534551   \n",
       "1997  125686.0  6.777829e+11  1.919710e+13 -7.724689e+13  5.200000  65.400002   \n",
       "1998  125944.0  7.079045e+11  1.927225e+13 -1.014742e+14  4.902281  64.235994   \n",
       "1999  130880.0  7.214590e+11  1.975110e+13 -9.646140e+13  5.264969  65.699997   \n",
       "2000  140547.0  7.396189e+11  2.055262e+13 -9.216180e+13  5.304083  62.707958   \n",
       "2001  136783.0  8.236331e+11  2.240717e+13 -6.621060e+13  5.249579  63.916000   \n",
       "2002  140315.0  8.834342e+11  2.412411e+13 -5.635700e+13  5.269189  63.299999   \n",
       "2003  139159.0  9.691983e+11  2.612031e+13 -1.853552e+14  5.500000  64.522871   \n",
       "2004  142379.0  1.054572e+12  2.874833e+13 -1.515222e+14  5.460000  62.906202   \n",
       "2005  161544.0  1.057680e+12  3.047457e+13 -1.350005e+14  5.206670  57.378561   \n",
       "2006  158888.0  1.203163e+12  3.469590e+13 -1.422689e+14  5.206982  55.474170   \n",
       "2007  161596.0  1.353147e+12  4.002108e+13 -1.691820e+14  5.000000  55.043033   \n",
       "\n",
       "               75%           max  \n",
       "1972  5.007000e+06  2.681335e+14  \n",
       "1973  7.131000e+06  2.943467e+14  \n",
       "1974  9.250000e+06  3.186506e+14  \n",
       "1975  1.108200e+07  3.383541e+14  \n",
       "1976  1.290000e+07  3.586152e+14  \n",
       "1977  1.540950e+07  3.895869e+14  \n",
       "1978  1.922850e+07  4.254506e+14  \n",
       "1979  2.409375e+07  4.556262e+14  \n",
       "1980  2.419225e+07  5.039050e+14  \n",
       "1981  2.317875e+07  5.815794e+14  \n",
       "1982  2.256215e+07  5.758716e+14  \n",
       "1983  2.350450e+07  6.003113e+14  \n",
       "1984  2.427000e+07  6.447141e+14  \n",
       "1985  2.448900e+07  6.806750e+14  \n",
       "1986  2.689850e+07  7.329650e+14  \n",
       "1987  2.689311e+07  8.034300e+14  \n",
       "1988  2.981823e+07  8.865110e+14  \n",
       "1989  2.869550e+07  9.735230e+14  \n",
       "1990  1.332700e+07  1.047622e+15  \n",
       "1991  1.692168e+07  1.097263e+15  \n",
       "1992  1.414500e+07  1.153124e+15  \n",
       "1993  1.545200e+07  1.192591e+15  \n",
       "1994  1.827500e+07  1.238312e+15  \n",
       "1995  1.779400e+07  1.342285e+15  \n",
       "1996  1.917926e+07  1.444873e+15  \n",
       "1997  1.900300e+07  1.517223e+15  \n",
       "1998  1.870445e+07  1.348416e+15  \n",
       "1999  1.300000e+07  1.324599e+15  \n",
       "2000  6.544000e+06  1.389770e+15  \n",
       "2001  1.038850e+07  1.646322e+15  \n",
       "2002  9.278000e+06  1.821833e+15  \n",
       "2003  1.200000e+07  2.013675e+15  \n",
       "2004  1.066050e+07  2.295826e+15  \n",
       "2005  8.484250e+06  2.774281e+15  \n",
       "2006  1.025022e+07  3.339217e+15  \n",
       "2007  8.599101e+06  3.950893e+15  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some basic stats about the training data\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Afghanistan', 'Albania', 'Algeria', 'American Samoa', 'Andorra',\n",
       "       'Angola', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba',\n",
       "       'Australia', 'Austria', 'Azerbaijan', 'Bahamas, The', 'Bahrain',\n",
       "       'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin',\n",
       "       'Bermuda', 'Bhutan', 'Bolivia', 'Bosnia and Herzegovina',\n",
       "       'Botswana', 'Brazil', 'Brunei Darussalam', 'Bulgaria',\n",
       "       'Burkina Faso', 'Burundi', 'Cabo Verde', 'Cambodia', 'Cameroon',\n",
       "       'Canada', 'Cayman Islands', 'Central African Republic', 'Chad',\n",
       "       'Channel Islands', 'Chile', 'China', 'Colombia', 'Comoros',\n",
       "       'Congo, Dem. Rep.', 'Congo, Rep.', 'Costa Rica', \"Cote d'Ivoire\",\n",
       "       'Croatia', 'Cuba', 'Curacao', 'Cyprus', 'Czech Republic',\n",
       "       'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador',\n",
       "       'Egypt, Arab Rep.', 'El Salvador', 'Equatorial Guinea', 'Eritrea',\n",
       "       'Estonia', 'Ethiopia', 'Faeroe Islands', 'Fiji', 'Finland',\n",
       "       'France', 'French Polynesia', 'Gabon', 'Gambia, The', 'Georgia',\n",
       "       'Germany', 'Ghana', 'Greece', 'Greenland', 'Grenada', 'Guam',\n",
       "       'Guatemala', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti',\n",
       "       'Honduras', 'Hong Kong SAR, China', 'Hungary', 'Iceland', 'India',\n",
       "       'Indonesia', 'Iran, Islamic Rep.', 'Iraq', 'Ireland',\n",
       "       'Isle of Man', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jordan',\n",
       "       'Kazakhstan', 'Kenya', 'Kiribati', 'Korea, Dem. Rep.',\n",
       "       'Korea, Rep.', 'Kosovo', 'Kuwait', 'Kyrgyz Republic', 'Lao PDR',\n",
       "       'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya',\n",
       "       'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macao SAR, China',\n",
       "       'Macedonia, FYR', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives',\n",
       "       'Mali', 'Malta', 'Marshall Islands', 'Mauritania', 'Mauritius',\n",
       "       'Mexico', 'Micronesia, Fed. Sts.', 'Moldova', 'Monaco', 'Mongolia',\n",
       "       'Montenegro', 'Morocco', 'Mozambique', 'Myanmar', 'Namibia',\n",
       "       'Nepal', 'Netherlands', 'New Caledonia', 'New Zealand',\n",
       "       'Nicaragua', 'Niger', 'Nigeria', 'Northern Mariana Islands',\n",
       "       'Norway', 'Oman', 'Pakistan', 'Palau', 'Panama',\n",
       "       'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland',\n",
       "       'Portugal', 'Puerto Rico', 'Qatar', 'Romania',\n",
       "       'Russian Federation', 'Rwanda', 'Samoa', 'San Marino',\n",
       "       'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Serbia',\n",
       "       'Seychelles', 'Sierra Leone', 'Singapore',\n",
       "       'Sint Maarten (Dutch part)', 'Slovak Republic', 'Slovenia',\n",
       "       'Solomon Islands', 'Somalia', 'South Africa', 'South Sudan',\n",
       "       'Spain', 'Sri Lanka', 'St. Kitts and Nevis', 'St. Lucia',\n",
       "       'St. Martin (French part)', 'St. Vincent and the Grenadines',\n",
       "       'Sudan', 'Suriname', 'Swaziland', 'Sweden', 'Switzerland',\n",
       "       'Syrian Arab Republic', 'Tajikistan', 'Tanzania', 'Thailand',\n",
       "       'Timor-Leste', 'Togo', 'Tonga', 'Trinidad and Tobago', 'Tunisia',\n",
       "       'Turkey', 'Turkmenistan', 'Turks and Caicos Islands', 'Tuvalu',\n",
       "       'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom',\n",
       "       'United States', 'Uruguay', 'Uzbekistan', 'Vanuatu',\n",
       "       'Venezuela, RB', 'Vietnam', 'Virgin Islands (U.S.)',\n",
       "       'West Bank and Gaza', 'Yemen, Rep.', 'Zambia', 'Zimbabwe'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of unique countries\n",
    "df.Country_Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct countries: 214\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of distinct countries: {df.Country_Name.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972            47534 \n",
       "1973            47677 \n",
       "1974            48521 \n",
       "1975            50269 \n",
       "1976            51279 \n",
       "1977            53185 \n",
       "1978            53578 \n",
       "1979            53882 \n",
       "1980            58032 \n",
       "1981            59693 \n",
       "1982            60516 \n",
       "1983            60615 \n",
       "1984            61088 \n",
       "1985            62170 \n",
       "1986            62726 \n",
       "1987            63482 \n",
       "1988            63814 \n",
       "1989            65248 \n",
       "1990            78732 \n",
       "1991            77506 \n",
       "1992            80642 \n",
       "1993            81969 \n",
       "1994            83600 \n",
       "1995            88951 \n",
       "1996            89206 \n",
       "1997            90177 \n",
       "1998            90256 \n",
       "1999            94957 \n",
       "2000            99186 \n",
       "2001            99397 \n",
       "2002            102167\n",
       "2003            101224\n",
       "2004            102863\n",
       "2005            111682\n",
       "2006            112989\n",
       "2007            115182\n",
       "Country_Name    214   \n",
       "Series_Code     1305  \n",
       "Series_Name     1305  \n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972            33.2% \n",
       "1973            33.0% \n",
       "1974            33.2% \n",
       "1975            34.3% \n",
       "1976            34.7% \n",
       "1977            35.7% \n",
       "1978            35.7% \n",
       "1979            35.8% \n",
       "1980            38.5% \n",
       "1981            39.9% \n",
       "1982            40.4% \n",
       "1983            40.4% \n",
       "1984            40.7% \n",
       "1985            41.5% \n",
       "1986            41.7% \n",
       "1987            42.3% \n",
       "1988            42.6% \n",
       "1989            44.2% \n",
       "1990            54.7% \n",
       "1991            54.8% \n",
       "1992            57.4% \n",
       "1993            58.6% \n",
       "1994            59.8% \n",
       "1995            63.7% \n",
       "1996            63.7% \n",
       "1997            64.3% \n",
       "1998            64.5% \n",
       "1999            67.0% \n",
       "2000            71.9% \n",
       "2001            70.0% \n",
       "2002            71.8% \n",
       "2003            71.2% \n",
       "2004            72.9% \n",
       "2005            82.7% \n",
       "2006            81.3% \n",
       "2007            82.7% \n",
       "Country_Name    100.0%\n",
       "Series_Code     100.0%\n",
       "Series_Name     100.0%\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of non-nul data in each column\n",
    "(df.count() / df.shape[0] * 100).map('{:.1f}%'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data containing the rows we need to predict\n",
    "df_submission = pd.read_csv('data/SubmissionRows.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2008 [YR2008]</th>\n",
       "      <th>2012 [YR2012]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2008 [YR2008]  2012 [YR2012]\n",
       "559  NaN            NaN           \n",
       "618  NaN            NaN           \n",
       "753  NaN            NaN           \n",
       "1030 NaN            NaN           \n",
       "1896 NaN            NaN           \n",
       "1955 NaN            NaN           \n",
       "2090 NaN            NaN           \n",
       "2690 NaN            NaN           \n",
       "3233 NaN            NaN           \n",
       "3292 NaN            NaN           "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have the row ID as an index for both the training (df) and the submission data, we can directly extract the data related to the submission index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_in_data = df.loc[df_submission.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission_in_data.Country_Name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the Series Code in the submission data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_codes = df_submission_in_data.Series_Code.unique()\n",
    "len(submission_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Series_Code.isin(submission_codes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or the percentage of non-nul data in each column\n",
    "(df.count() / df.shape[0] * 100).iloc[:-4].plot(label='training')\n",
    "(df_submission_in_data.count() / df_submission_in_data.shape[0] * 100).iloc[:-4].plot(label='submission')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have learned from the analysis of the submission data that:\n",
    "1. Most countries are represented in the submission data, 206 out of 214\n",
    "2. Only 7 codes are used and we have 1118 data points in the training data with these codes\n",
    "3. The amount of missing data is fairly similar between the training and submission data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we trying to achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 737 indicators from 206 countries with data from 1972 to 2007.  \n",
    "We would like to predict what these indicators will be in 2008 and 2012.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simplistic way of predicting the future values of these indicators would be to do a simple linear regression for indicators with more than 1 data point in the last 35 years or use the only data point we have for indicators with a single value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try to code this simplistic version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(row):\n",
    "    data = row.loc['1972':'2007']\n",
    "    nbr_data_points = data.count()\n",
    "    if nbr_data_points < 2:\n",
    "        pred_2008 = data.dropna().values\n",
    "        pred_2012 = pred_2008\n",
    "    \n",
    "    else:\n",
    "        years = data.dropna().index.values.astype(np.int).reshape(-1, 1)\n",
    "        values = data.dropna().values\n",
    "        \n",
    "        #linear regression\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(years, values)\n",
    "        \n",
    "        #predictions\n",
    "        pred_2008 = regr.predict(np.array([2008]).reshape(-1, 1))\n",
    "        pred_2012 = regr.predict(np.array([2012]).reshape(-1, 1))\n",
    "        \n",
    "    return pred_2008[0], pred_2012[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_preds = pd.DataFrame(df_submission_in_data.apply(make_prediction, axis=1).tolist(), index=df_submission_in_data.index, columns=['2008','2012'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(df_train, df_pred, nbr_rows):\n",
    "    rows_to_plot = np.random.choice(df_train.index.values, nbr_rows, replace=False)\n",
    "    \n",
    "    cmap = get_cmap('Set1')\n",
    "    colors = cmap.colors\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    for i,j in zip(rows_to_plot, range(nbr_rows)):\n",
    "        if j >= len(colors): j -= len(colors)\n",
    "        ax.plot(df_train.loc[i, '1972':'2007'].dropna().index.astype(int), \n",
    "                df_train.loc[i, '1972':'2007'].dropna().values, \n",
    "                label=df_train.loc[i, 'Country_Name']+ '/' + df_train.loc[i, 'Series_Name'],\n",
    "                marker='o',\n",
    "                linewidth=4,\n",
    "                alpha=0.5,\n",
    "                color=colors[j])\n",
    "                \n",
    "        ax.plot(df_pred.loc[i].index.astype(int), \n",
    "                df_pred.loc[i].values,\n",
    "                marker='s',\n",
    "                linewidth=4,\n",
    "                markersize=10,\n",
    "                color=colors[j])\n",
    "\n",
    "    plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(df_submission_in_data, df_simple_preds, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are simplistic but not too bad for most indicators.  \n",
    "We could improve easily the results by doing a polynomial regression or another type of more sophisticated regression.  \n",
    "\n",
    "But what we are trying to achieve is find correlation between these indicators and all the other indicators present in the dataset to improve our predictions as we have a lot of missing data.  \n",
    "And these predictions using correlations are where the difficulty of this exercise lies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating sub codes from the main code values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first make all values upper case to make sure we compare correctly the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Series_Code = df.Series_Code.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Series_Code.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1305 different code names but most of them include similar codes which might be helpful when trying to find similarity within the data to help with our predictions.  \n",
    "We will create a function that extract each of the subcodes and save them in separate column in function of their order in the code serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the code structure\n",
    "df.Series_Code.apply(lambda x: len(x.split('.'))).plot(kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_longest_code_serie = df.Series_Code.apply(lambda x: len(x.split('.'))).idxmax()\n",
    "df.loc[row_longest_code_serie, 'Series_Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[row_longest_code_serie, 'Series_Code'].split('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a maximum of 7 separate elements in the code structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_code(s):\n",
    "    # split the code name using the '.'\n",
    "    s_split = s.split('.')\n",
    "    \n",
    "    # save the first and last value of the serie\n",
    "    last = s_split[-1]\n",
    "    first = s_split[0]\n",
    "    \n",
    "    # reverse the order of the code series to keep the last code as first and first as last\n",
    "    #s_split = s_split[::-1]\n",
    "    \n",
    "    # add NaN values until the list has 7 items in it\n",
    "    s_split += [np.NaN] * (7 - len(s_split))\n",
    "    \n",
    "    # add the first and last value to the list\n",
    "    s_split += [first, last]\n",
    "    \n",
    "    return s_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create 9 new columns for each of the output of the function explode_code\n",
    "# fill these columns with the ouput of the explode_code function by converting its ouput to a list and then to a dataframe using the orginal index of the dataframe\n",
    "\n",
    "df[['Series_Code_'+ str(i) for i in range(7)] + ['Series_Code_First', 'Series_Code_Last']] =\\\n",
    "    pd.DataFrame(df.Series_Code.apply(explode_code).tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:5,-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-5:,-11:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the continent related to each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import countryinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continent = pd.DataFrame(countryinfo.countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continent.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We copy the continent information from the dataframe using the country names as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the map function of pandas for looking the the country name in the index of the second df and outputing the continent information\n",
    "df['Continent'] = df.Country_Name.map(df_continent.set_index('name').continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Continent','Country_Name']].iloc[::15000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some countries with names that are different from our list of country/continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Continent.isna()].Country_Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Country_Name.str.contains('Bahamas', case=False)].Country_Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continent[df_continent.name.str.contains('Bahamas', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continent missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some fuzzy matching to find the most likely candidate for the country listed in our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_bad_name = df[df.Continent.isna()].Country_Name.unique()\n",
    "countries = df_continent.name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = country_bad_name[0]\n",
    "print(country)\n",
    "process.extractOne(country, countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fuzzy = pd.DataFrame([[country]+list(process.extractOne(country, countries)) for country in country_bad_name], \n",
    "                        columns=['training_name', 'replacement_name', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fuzzy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the continent to this dataframe\n",
    "df_fuzzy['Continent'] = df_fuzzy.replacement_name.map(df_continent.set_index('name').continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fuzzy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement_name that we are most sure about\n",
    "df_fuzzy[df_fuzzy.score > 86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement_name that we are most sure about\n",
    "df_fuzzy[df_fuzzy.score < 86]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are missing a few easy fix like Congo and Korea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill the missing continents using the above rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_to_correct = df.Country_Name.isin(df_fuzzy[df_fuzzy.score > 86].training_name)\n",
    "\n",
    "df.loc[countries_to_correct, 'Continent'] =\\\n",
    "    df.loc[countries_to_correct, 'Country_Name'].map(\n",
    "        df_fuzzy[df_fuzzy.score > 86].set_index('training_name').Continent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's redo the above fuzzy matching but trying a different metric to catch more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_bad_name = df[df.Continent.isna()].Country_Name.unique()\n",
    "countries = df_continent.name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = country_bad_name[5]\n",
    "print(country)\n",
    "print(process.extractOne(country, countries))\n",
    "print(process.extractOne(country, countries, scorer=fuzz.ratio))\n",
    "print(process.extractOne(country, countries, scorer=fuzz.partial_ratio))\n",
    "print(process.extractOne(country, countries, scorer=fuzz.token_sort_ratio))\n",
    "print(process.extractOne(country, countries, scorer=fuzz.token_set_ratio))\n",
    "print(process.extractOne(country, countries, scorer=fuzz.partial_token_set_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fuzzy = pd.DataFrame([[country]+list(process.extractOne(country, \n",
    "                                                           countries, \n",
    "                                                           scorer=fuzz.ratio\n",
    "                                                          )) for country in country_bad_name], \n",
    "                        columns=['training_name', 'replacement_name', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the continent to this dataframe\n",
    "df_fuzzy['Continent'] = df_fuzzy.replacement_name.map(df_continent.set_index('name').continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement_name that we are most sure about\n",
    "df_fuzzy[df_fuzzy.score > 79]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill the missing continents using the above rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_to_correct = df.Country_Name.isin(df_fuzzy[df_fuzzy.score > 79].training_name)\n",
    "\n",
    "df.loc[countries_to_correct, 'Continent'] =\\\n",
    "    df.loc[countries_to_correct, 'Country_Name'].map(\n",
    "        df_fuzzy[df_fuzzy.score > 79].set_index('training_name').Continent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual corrections for Korea, Congo and China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continent[df_continent.name.str.contains('congo', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continent[df_continent.name.str.contains('korea', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Country_Name.str.contains('congo', case=False), 'Continent'] = 'Africa'\n",
    "df.loc[df.Country_Name.str.contains('korea', case=False), 'Continent'] = 'Asia'\n",
    "df.loc[df.Country_Name.str.contains('china', case=False), 'Continent'] = 'Asia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is left in our missing continent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_bad_name = df[df.Continent.isna()].Country_Name.unique()\n",
    "country_bad_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(country_bad_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Country_Name.isin(country_bad_name).sum() / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_in_data.Country_Name.isin(country_bad_name).sum() / df_submission_in_data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have less than 5% of the data with a missing continent in the training and submission data so we can probably leave it as it is and just replace it with Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Country_Name.isin(country_bad_name), 'Continent'] = 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the subcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 most common subcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df.loc[:, 'Series_Code_0':'Series_Code_Last'].values.flat).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common codes for each subcode column ignoring the nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_code(array, codes):\n",
    "    array_notna = array[~pd.isna(array)]\n",
    "    common_code = np.array(Counter(array_notna).most_common(codes))[:,0]\n",
    "    common_code = np.append(common_code, [np.nan]*(codes-len(common_code)))\n",
    "    return common_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data= np.apply_along_axis(func1d=most_common_code, \n",
    "                                       arr=df.loc[:, 'Series_Code_0':'Series_Code_Last'].values,\n",
    "                                       axis=0,\n",
    "                                      codes=15), \n",
    "             columns=df.loc[:, 'Series_Code_0':'Series_Code_Last'].columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
